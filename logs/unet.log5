True
device: cuda
{'weight': 'unet', 'one_hot': False, 'lr': 0.001, 'batch_size': 256, 'epochs': 100, 'channels': [16, 16, 32, 64, 64], 'drop_out': 0}
Encoder_v3(
  (model): Sequential(
    (0): Conv1d(768, 16, kernel_size=(31,), stride=(1,), padding=(15,))
    (1): ResnetBlock(
      (norm1): GroupNorm(16, 16, eps=1e-06, affine=True)
      (conv1): Conv1d(16, 16, kernel_size=(9,), stride=(1,), padding=(4,))
      (norm2): GroupNorm(16, 16, eps=1e-06, affine=True)
      (dropout): Dropout(p=0, inplace=False)
      (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (2): ResnetBlock(
      (norm1): GroupNorm(16, 16, eps=1e-06, affine=True)
      (conv1): Conv1d(16, 16, kernel_size=(9,), stride=(1,), padding=(4,))
      (norm2): GroupNorm(16, 16, eps=1e-06, affine=True)
      (dropout): Dropout(p=0, inplace=False)
      (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (3): ResnetBlock(
      (norm1): GroupNorm(16, 16, eps=1e-06, affine=True)
      (conv1): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(4,))
      (norm2): GroupNorm(16, 32, eps=1e-06, affine=True)
      (dropout): Dropout(p=0, inplace=False)
      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (nin_shortcut): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
    )
    (4): ResnetBlock(
      (norm1): GroupNorm(16, 32, eps=1e-06, affine=True)
      (conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 32, eps=1e-06, affine=True)
      (dropout): Dropout(p=0, inplace=False)
      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (5): ResnetBlock(
      (norm1): GroupNorm(16, 32, eps=1e-06, affine=True)
      (conv1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 64, eps=1e-06, affine=True)
      (dropout): Dropout(p=0, inplace=False)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (nin_shortcut): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
    )
    (6): ResnetBlock(
      (norm1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 64, eps=1e-06, affine=True)
      (dropout): Dropout(p=0, inplace=False)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (7): ResnetBlock(
      (norm1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 64, eps=1e-06, affine=True)
      (dropout): Dropout(p=0, inplace=False)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (8): ResnetBlock(
      (norm1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 64, eps=1e-06, affine=True)
      (dropout): Dropout(p=0, inplace=False)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (9): ResnetBlock(
      (norm1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 64, eps=1e-06, affine=True)
      (dropout): Dropout(p=0, inplace=False)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (10): ResnetBlock(
      (norm1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 64, eps=1e-06, affine=True)
      (dropout): Dropout(p=0, inplace=False)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (11): GroupNorm(16, 64, eps=1e-06, affine=True)
    (12): Swish()
    (13): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
  )
  (final): Linear(in_features=128000, out_features=36, bias=True)
  (dnaemb): Embedding(5, 768)
)
x: torch.Size([256, 1, 1000])
y: torch.Size([256, 36])

------- Start Training --------
Traceback (most recent call last):
  File "/home/wenduoc/mambaforge/envs/geneorca/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/home/wenduoc/mambaforge/envs/geneorca/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wenduoc/mambaforge/envs/geneorca/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wenduoc/mambaforge/envs/geneorca/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
[train full 0 0.001000 ] time elapsed: 39.1658 	train loss: 0.9474 	val loss: 0.9331 	val score: 0.4858 	best val score: 0.4858
[train full 1 0.001000 ] time elapsed: 35.5178 	train loss: 0.9386 	val loss: 0.9329 	val score: 0.4842 	best val score: 0.4842
[train full 2 0.001000 ] time elapsed: 38.2676 	train loss: 0.9386 	val loss: 0.9328 	val score: 0.4834 	best val score: 0.4834
[train full 3 0.001000 ] time elapsed: 36.5929 	train loss: 0.9406 	val loss: 0.9328 	val score: 0.4829 	best val score: 0.4829
Traceback (most recent call last):
  File "pretrain_embedder.py", line 490, in <module>
    train_loss = train_one_epoch(model, optimizer, scheduler, train_loader, loss, n_train)
  File "pretrain_embedder.py", line 460, in train_one_epoch
    l.backward()
  File "/home/wenduoc/mambaforge/envs/geneorca/lib/python3.8/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/home/wenduoc/mambaforge/envs/geneorca/lib/python3.8/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
