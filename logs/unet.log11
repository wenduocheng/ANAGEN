True
device: cuda
{'weight': 'unet', 'one_hot': True, 'lr': 0.001, 'batch_size': 256, 'epochs': 100, 'channels': [16, 16, 32, 32, 64, 64], 'drop_out': 0.2}
Encoder_v2(
  (model): Sequential(
    (0): Conv1d(4, 16, kernel_size=(31,), stride=(1,), padding=(15,))
    (1): ResnetBlock(
      (norm1): GroupNorm(16, 16, eps=1e-06, affine=True)
      (conv1): Conv1d(16, 16, kernel_size=(9,), stride=(1,), padding=(4,))
      (norm2): GroupNorm(16, 16, eps=1e-06, affine=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (2): ResnetBlock(
      (norm1): GroupNorm(16, 16, eps=1e-06, affine=True)
      (conv1): Conv1d(16, 16, kernel_size=(9,), stride=(1,), padding=(4,))
      (norm2): GroupNorm(16, 16, eps=1e-06, affine=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (3): ResnetBlock(
      (norm1): GroupNorm(16, 16, eps=1e-06, affine=True)
      (conv1): Conv1d(16, 32, kernel_size=(9,), stride=(1,), padding=(4,))
      (norm2): GroupNorm(16, 32, eps=1e-06, affine=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (nin_shortcut): Conv1d(16, 32, kernel_size=(1,), stride=(1,))
    )
    (4): ResnetBlock(
      (norm1): GroupNorm(16, 32, eps=1e-06, affine=True)
      (conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 32, eps=1e-06, affine=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (5): ResnetBlock(
      (norm1): GroupNorm(16, 32, eps=1e-06, affine=True)
      (conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 32, eps=1e-06, affine=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (6): ResnetBlock(
      (norm1): GroupNorm(16, 32, eps=1e-06, affine=True)
      (conv1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 32, eps=1e-06, affine=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (7): ResnetBlock(
      (norm1): GroupNorm(16, 32, eps=1e-06, affine=True)
      (conv1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 64, eps=1e-06, affine=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (nin_shortcut): Conv1d(32, 64, kernel_size=(1,), stride=(1,))
    )
    (8): ResnetBlock(
      (norm1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 64, eps=1e-06, affine=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (9): ResnetBlock(
      (norm1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 64, eps=1e-06, affine=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (10): ResnetBlock(
      (norm1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 64, eps=1e-06, affine=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (11): ResnetBlock(
      (norm1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 64, eps=1e-06, affine=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (12): ResnetBlock(
      (norm1): GroupNorm(16, 64, eps=1e-06, affine=True)
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (norm2): GroupNorm(16, 64, eps=1e-06, affine=True)
      (dropout): Dropout(p=0.2, inplace=False)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (13): GroupNorm(16, 64, eps=1e-06, affine=True)
    (14): Swish()
    (15): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))
  )
  (final): Linear(in_features=128000, out_features=36, bias=True)
)
x: torch.Size([256, 4, 1000])
y: torch.Size([256, 36])

------- Start Training --------
Traceback (most recent call last):
  File "/home/wenduoc/mambaforge/envs/geneorca/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/home/wenduoc/mambaforge/envs/geneorca/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wenduoc/mambaforge/envs/geneorca/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wenduoc/mambaforge/envs/geneorca/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
[train full 0 0.001000 ] time elapsed: 38.9764 	train loss: 0.8740 	val loss: 0.8583 	val score: 0.4758 	best val score: 0.4758
[train full 1 0.001000 ] time elapsed: 29.4820 	train loss: 0.8627 	val loss: 0.8453 	val score: 0.4275 	best val score: 0.4275
[train full 2 0.001000 ] time elapsed: 28.7560 	train loss: 0.8456 	val loss: 0.8305 	val score: 0.3934 	best val score: 0.3934
[train full 3 0.001000 ] time elapsed: 27.1328 	train loss: 0.8334 	val loss: 0.8639 	val score: 0.3801 	best val score: 0.3801
[train full 4 0.001000 ] time elapsed: 30.0224 	train loss: 0.8270 	val loss: 0.8243 	val score: 0.3779 	best val score: 0.3779
[train full 5 0.001000 ] time elapsed: 29.5347 	train loss: 0.8176 	val loss: 0.8250 	val score: 0.3756 	best val score: 0.3756
[train full 6 0.001000 ] time elapsed: 28.0271 	train loss: 0.8144 	val loss: 0.8240 	val score: 0.3748 	best val score: 0.3748
[train full 7 0.001000 ] time elapsed: 30.3354 	train loss: 0.8098 	val loss: 0.8243 	val score: 0.3743 	best val score: 0.3743
[train full 8 0.001000 ] time elapsed: 30.3910 	train loss: 0.8066 	val loss: 0.8300 	val score: 0.3742 	best val score: 0.3742
[train full 9 0.001000 ] time elapsed: 29.5534 	train loss: 0.8034 	val loss: 0.8313 	val score: 0.3747 	best val score: 0.3742
[train full 10 0.001000 ] time elapsed: 29.7934 	train loss: 0.8013 	val loss: 0.8285 	val score: 0.3747 	best val score: 0.3742
[train full 11 0.001000 ] time elapsed: 29.2592 	train loss: 0.7969 	val loss: 0.8305 	val score: 0.3757 	best val score: 0.3742
[train full 12 0.001000 ] time elapsed: 28.8025 	train loss: 0.7933 	val loss: 0.8294 	val score: 0.3764 	best val score: 0.3742
[train full 13 0.001000 ] time elapsed: 32.2783 	train loss: 0.7906 	val loss: 0.8311 	val score: 0.3770 	best val score: 0.3742
[train full 14 0.001000 ] time elapsed: 28.8147 	train loss: 0.7874 	val loss: 0.8344 	val score: 0.3775 	best val score: 0.3742
[train full 15 0.001000 ] time elapsed: 32.1069 	train loss: 0.7846 	val loss: 0.8358 	val score: 0.3786 	best val score: 0.3742
[train full 16 0.001000 ] time elapsed: 33.5884 	train loss: 0.7842 	val loss: 0.8347 	val score: 0.3797 	best val score: 0.3742
[train full 17 0.001000 ] time elapsed: 28.5119 	train loss: 0.7792 	val loss: 0.8432 	val score: 0.3799 	best val score: 0.3742
[train full 18 0.001000 ] time elapsed: 30.5846 	train loss: 0.7749 	val loss: 0.8439 	val score: 0.3802 	best val score: 0.3742
[train full 19 0.001000 ] time elapsed: 30.2283 	train loss: 0.7725 	val loss: 0.8405 	val score: 0.3806 	best val score: 0.3742
[train full 20 0.001000 ] time elapsed: 31.0771 	train loss: 0.7694 	val loss: 0.8416 	val score: 0.3794 	best val score: 0.3742
[train full 21 0.001000 ] time elapsed: 29.1870 	train loss: 0.7652 	val loss: 0.8421 	val score: 0.3801 	best val score: 0.3742
[train full 22 0.001000 ] time elapsed: 31.7222 	train loss: 0.7628 	val loss: 0.8612 	val score: 0.3830 	best val score: 0.3742
[train full 23 0.001000 ] time elapsed: 30.4700 	train loss: 0.7611 	val loss: 0.8454 	val score: 0.3808 	best val score: 0.3742
[train full 24 0.001000 ] time elapsed: 29.0088 	train loss: 0.7562 	val loss: 0.8530 	val score: 0.3816 	best val score: 0.3742
[train full 25 0.001000 ] time elapsed: 31.1101 	train loss: 0.7545 	val loss: 0.8503 	val score: 0.3821 	best val score: 0.3742
[train full 26 0.001000 ] time elapsed: 30.0309 	train loss: 0.7502 	val loss: 0.8503 	val score: 0.3808 	best val score: 0.3742
[train full 27 0.001000 ] time elapsed: 27.6077 	train loss: 0.7478 	val loss: 0.8589 	val score: 0.3828 	best val score: 0.3742
[train full 28 0.001000 ] time elapsed: 31.8640 	train loss: 0.7447 	val loss: 0.8552 	val score: 0.3831 	best val score: 0.3742
[train full 29 0.001000 ] time elapsed: 31.0676 	train loss: 0.7436 	val loss: 0.8541 	val score: 0.3817 	best val score: 0.3742
[train full 30 0.000200 ] time elapsed: 28.6589 	train loss: 0.7428 	val loss: 0.8622 	val score: 0.3821 	best val score: 0.3742
[train full 31 0.000200 ] time elapsed: 28.7890 	train loss: 0.7327 	val loss: 0.8573 	val score: 0.3831 	best val score: 0.3742
[train full 32 0.000200 ] time elapsed: 31.6580 	train loss: 0.7308 	val loss: 0.8564 	val score: 0.3831 	best val score: 0.3742
[train full 33 0.000200 ] time elapsed: 27.3461 	train loss: 0.7306 	val loss: 0.8566 	val score: 0.3829 	best val score: 0.3742
[train full 34 0.000200 ] time elapsed: 31.5684 	train loss: 0.7303 	val loss: 0.8584 	val score: 0.3833 	best val score: 0.3742
[train full 35 0.000200 ] time elapsed: 29.8851 	train loss: 0.7290 	val loss: 0.8574 	val score: 0.3829 	best val score: 0.3742
[train full 36 0.000200 ] time elapsed: 31.1117 	train loss: 0.7285 	val loss: 0.8594 	val score: 0.3832 	best val score: 0.3742
[train full 37 0.000200 ] time elapsed: 30.2045 	train loss: 0.7292 	val loss: 0.8587 	val score: 0.3830 	best val score: 0.3742
[train full 38 0.000200 ] time elapsed: 31.2776 	train loss: 0.7274 	val loss: 0.8609 	val score: 0.3833 	best val score: 0.3742
[train full 39 0.000200 ] time elapsed: 30.5907 	train loss: 0.7270 	val loss: 0.8599 	val score: 0.3835 	best val score: 0.3742
[train full 40 0.000200 ] time elapsed: 31.6686 	train loss: 0.7256 	val loss: 0.8590 	val score: 0.3829 	best val score: 0.3742
[train full 41 0.000200 ] time elapsed: 30.0048 	train loss: 0.7248 	val loss: 0.8614 	val score: 0.3835 	best val score: 0.3742
[train full 42 0.000200 ] time elapsed: 30.2743 	train loss: 0.7247 	val loss: 0.8606 	val score: 0.3836 	best val score: 0.3742
[train full 43 0.000200 ] time elapsed: 29.7146 	train loss: 0.7238 	val loss: 0.8600 	val score: 0.3831 	best val score: 0.3742
[train full 44 0.000200 ] time elapsed: 31.7800 	train loss: 0.7253 	val loss: 0.8600 	val score: 0.3830 	best val score: 0.3742
[train full 45 0.000200 ] time elapsed: 27.7410 	train loss: 0.7242 	val loss: 0.8609 	val score: 0.3832 	best val score: 0.3742
[train full 46 0.000200 ] time elapsed: 31.7259 	train loss: 0.7220 	val loss: 0.8625 	val score: 0.3836 	best val score: 0.3742
[train full 47 0.000200 ] time elapsed: 31.2211 	train loss: 0.7201 	val loss: 0.8635 	val score: 0.3838 	best val score: 0.3742
[train full 48 0.000200 ] time elapsed: 28.9751 	train loss: 0.7205 	val loss: 0.8621 	val score: 0.3840 	best val score: 0.3742
[train full 49 0.000200 ] time elapsed: 28.5617 	train loss: 0.7190 	val loss: 0.8640 	val score: 0.3835 	best val score: 0.3742
[train full 50 0.000200 ] time elapsed: 29.2039 	train loss: 0.7189 	val loss: 0.8647 	val score: 0.3839 	best val score: 0.3742
[train full 51 0.000200 ] time elapsed: 29.3793 	train loss: 0.7190 	val loss: 0.8656 	val score: 0.3838 	best val score: 0.3742
[train full 52 0.000200 ] time elapsed: 30.1907 	train loss: 0.7177 	val loss: 0.8635 	val score: 0.3838 	best val score: 0.3742
[train full 53 0.000200 ] time elapsed: 32.2289 	train loss: 0.7170 	val loss: 0.8657 	val score: 0.3839 	best val score: 0.3742
[train full 54 0.000200 ] time elapsed: 29.8758 	train loss: 0.7173 	val loss: 0.8633 	val score: 0.3835 	best val score: 0.3742
[train full 55 0.000200 ] time elapsed: 32.5612 	train loss: 0.7185 	val loss: 0.8637 	val score: 0.3836 	best val score: 0.3742
[train full 56 0.000200 ] time elapsed: 29.7573 	train loss: 0.7148 	val loss: 0.8652 	val score: 0.3841 	best val score: 0.3742
[train full 57 0.000200 ] time elapsed: 29.0428 	train loss: 0.7148 	val loss: 0.8655 	val score: 0.3838 	best val score: 0.3742
[train full 58 0.000200 ] time elapsed: 30.5525 	train loss: 0.7136 	val loss: 0.8676 	val score: 0.3844 	best val score: 0.3742
[train full 59 0.000200 ] time elapsed: 26.9286 	train loss: 0.7162 	val loss: 0.8649 	val score: 0.3838 	best val score: 0.3742
[train full 60 0.000040 ] time elapsed: 29.9004 	train loss: 0.7133 	val loss: 0.8660 	val score: 0.3840 	best val score: 0.3742
[train full 61 0.000040 ] time elapsed: 30.5071 	train loss: 0.7122 	val loss: 0.8671 	val score: 0.3841 	best val score: 0.3742
[train full 62 0.000040 ] time elapsed: 30.2044 	train loss: 0.7107 	val loss: 0.8681 	val score: 0.3842 	best val score: 0.3742
[train full 63 0.000040 ] time elapsed: 30.3299 	train loss: 0.7124 	val loss: 0.8682 	val score: 0.3843 	best val score: 0.3742
[train full 64 0.000040 ] time elapsed: 28.3402 	train loss: 0.7088 	val loss: 0.8675 	val score: 0.3842 	best val score: 0.3742
[train full 65 0.000040 ] time elapsed: 33.8414 	train loss: 0.7095 	val loss: 0.8681 	val score: 0.3842 	best val score: 0.3742
[train full 66 0.000040 ] time elapsed: 31.3944 	train loss: 0.7106 	val loss: 0.8676 	val score: 0.3841 	best val score: 0.3742
[train full 67 0.000040 ] time elapsed: 29.1835 	train loss: 0.7098 	val loss: 0.8678 	val score: 0.3841 	best val score: 0.3742
[train full 68 0.000040 ] time elapsed: 30.1055 	train loss: 0.7100 	val loss: 0.8675 	val score: 0.3840 	best val score: 0.3742
[train full 69 0.000040 ] time elapsed: 28.4131 	train loss: 0.7113 	val loss: 0.8684 	val score: 0.3841 	best val score: 0.3742
[train full 70 0.000040 ] time elapsed: 30.1403 	train loss: 0.7097 	val loss: 0.8679 	val score: 0.3839 	best val score: 0.3742
[train full 71 0.000040 ] time elapsed: 31.1891 	train loss: 0.7097 	val loss: 0.8678 	val score: 0.3839 	best val score: 0.3742
[train full 72 0.000040 ] time elapsed: 31.5752 	train loss: 0.7087 	val loss: 0.8687 	val score: 0.3842 	best val score: 0.3742
[train full 73 0.000040 ] time elapsed: 31.6043 	train loss: 0.7092 	val loss: 0.8685 	val score: 0.3842 	best val score: 0.3742
[train full 74 0.000040 ] time elapsed: 30.8620 	train loss: 0.7093 	val loss: 0.8684 	val score: 0.3842 	best val score: 0.3742
[train full 75 0.000040 ] time elapsed: 30.7594 	train loss: 0.7079 	val loss: 0.8688 	val score: 0.3842 	best val score: 0.3742
[train full 76 0.000040 ] time elapsed: 30.5905 	train loss: 0.7083 	val loss: 0.8687 	val score: 0.3842 	best val score: 0.3742
[train full 77 0.000040 ] time elapsed: 32.3671 	train loss: 0.7088 	val loss: 0.8697 	val score: 0.3843 	best val score: 0.3742
[train full 78 0.000040 ] time elapsed: 30.2065 	train loss: 0.7080 	val loss: 0.8678 	val score: 0.3841 	best val score: 0.3742
[train full 79 0.000040 ] time elapsed: 28.2946 	train loss: 0.7078 	val loss: 0.8690 	val score: 0.3843 	best val score: 0.3742
[train full 80 0.000040 ] time elapsed: 27.4967 	train loss: 0.7090 	val loss: 0.8698 	val score: 0.3844 	best val score: 0.3742
[train full 81 0.000040 ] time elapsed: 29.8856 	train loss: 0.7090 	val loss: 0.8692 	val score: 0.3843 	best val score: 0.3742
[train full 82 0.000040 ] time elapsed: 29.3481 	train loss: 0.7082 	val loss: 0.8688 	val score: 0.3841 	best val score: 0.3742
[train full 83 0.000040 ] time elapsed: 29.6271 	train loss: 0.7079 	val loss: 0.8698 	val score: 0.3842 	best val score: 0.3742
[train full 84 0.000040 ] time elapsed: 31.0418 	train loss: 0.7084 	val loss: 0.8692 	val score: 0.3843 	best val score: 0.3742
[train full 85 0.000040 ] time elapsed: 29.3502 	train loss: 0.7082 	val loss: 0.8689 	val score: 0.3843 	best val score: 0.3742
[train full 86 0.000040 ] time elapsed: 31.4315 	train loss: 0.7066 	val loss: 0.8694 	val score: 0.3844 	best val score: 0.3742
[train full 87 0.000040 ] time elapsed: 32.5505 	train loss: 0.7064 	val loss: 0.8697 	val score: 0.3844 	best val score: 0.3742
[train full 88 0.000040 ] time elapsed: 29.0956 	train loss: 0.7065 	val loss: 0.8696 	val score: 0.3844 	best val score: 0.3742
[train full 89 0.000040 ] time elapsed: 29.8343 	train loss: 0.7081 	val loss: 0.8694 	val score: 0.3843 	best val score: 0.3742
[train full 90 0.000008 ] time elapsed: 32.1010 	train loss: 0.7086 	val loss: 0.8700 	val score: 0.3843 	best val score: 0.3742
[train full 91 0.000008 ] time elapsed: 29.6869 	train loss: 0.7063 	val loss: 0.8699 	val score: 0.3843 	best val score: 0.3742
[train full 92 0.000008 ] time elapsed: 30.6959 	train loss: 0.7062 	val loss: 0.8696 	val score: 0.3842 	best val score: 0.3742
[train full 93 0.000008 ] time elapsed: 29.6403 	train loss: 0.7092 	val loss: 0.8696 	val score: 0.3843 	best val score: 0.3742
[train full 94 0.000008 ] time elapsed: 28.4076 	train loss: 0.7064 	val loss: 0.8696 	val score: 0.3843 	best val score: 0.3742
[train full 95 0.000008 ] time elapsed: 30.0276 	train loss: 0.7064 	val loss: 0.8696 	val score: 0.3843 	best val score: 0.3742
[train full 96 0.000008 ] time elapsed: 30.2045 	train loss: 0.7065 	val loss: 0.8693 	val score: 0.3843 	best val score: 0.3742
[train full 97 0.000008 ] time elapsed: 29.1978 	train loss: 0.7078 	val loss: 0.8697 	val score: 0.3843 	best val score: 0.3742
[train full 98 0.000008 ] time elapsed: 28.9898 	train loss: 0.7060 	val loss: 0.8696 	val score: 0.3843 	best val score: 0.3742
[train full 99 0.000008 ] time elapsed: 29.3943 	train loss: 0.7065 	val loss: 0.8696 	val score: 0.3843 	best val score: 0.3742

------- Start Test --------
[test last] 	time elapsed: 41.9145 	test loss: 0.8696 	test score: 0.3843 	second test score: 0.8145
